{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "Jithin Eapen (CWID - 893390096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Computational Graph for a single Perceptron\n",
    "x1 -----\\\n",
    "         \\\n",
    "          \\\n",
    "          \n",
    "          sig(w1 * x1 + w2 * x2 + b) ---- O (L)\n",
    "          /\n",
    "         /\n",
    "x2 -----/        \n",
    "```\n",
    "\n",
    "here `O` is the output of the perceptron and `L` is the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ref: Sigmoid Gradient\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\delta \\sigma(x)}{\\delta x} = \\sigma(x)(1 - \\sigma(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Other gradients can be easily calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Generic class definitions for various operators/nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Base object for all inputs and outputs.\n",
    "    \"\"\"\n",
    "    def __init__(self, value, grad):\n",
    "        self.value = value\n",
    "        self.gradient = grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplyNode(object):\n",
    "    \"\"\"\n",
    "    Multiplies two inputs\n",
    "    \"\"\"\n",
    "    def forward(self, x1, x2):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.output = Node(self.x1.value * self.x2.value, 0)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self):\n",
    "        self.x1.gradient = self.x2.value * self.output.gradient\n",
    "        self.x2.gradient = self.x1.value * self.output.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNode(object):    \n",
    "    \"\"\"\n",
    "    Adds two inputs x1 and x2.\n",
    "    \"\"\"\n",
    "    def forward(self, x1, x2):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.output = Node(self.x1.value + self.x2.value, 0)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self):\n",
    "        self.x1.gradient = 1 * self.output.gradient\n",
    "        self.x2.gradient = 1 * self.output.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidNode(object):\n",
    "    \"\"\"\n",
    "    Adds a sigmoid non-linearity to a single input\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.output = Node(1/(1 + np.exp(-1 * self.x.value)), 0.0)\n",
    "        return self.output\n",
    "        \n",
    "    def backward(self):\n",
    "        s = 1/(1 + np.exp(-1 * self.x.value))\n",
    "        self.x.gradient = (s * (1 - s)) * self.output.gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Putting it all together into a single Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, x1, x2, alpha=0.001):\n",
    "        ### Hyper parameters\n",
    "        self.alpha = alpha\n",
    "        ### Initializing weights/bias to a random float between -1 and 1.\n",
    "        self.w1 = Node(np.random.uniform(-1, 1), 0.0)\n",
    "        self.w2 = Node(np.random.uniform(-1, 1), 0.0)\n",
    "        self.b = Node(np.random.uniform(-1, 1), 0.0)\n",
    "        ### Input and Output variables\n",
    "        self.x1 = Node(x1, 0.0)\n",
    "        self.x2 = Node(x2, 0.0)\n",
    "        ### Initialize operators nodes required \n",
    "        ### for processing the inputs within a perceptron\n",
    "        self.initialize_operators()\n",
    "    \n",
    "    def initialize_operators(self):\n",
    "        self.w1_mul_x1 = MultiplyNode()\n",
    "        self.w2_mul_x2 = MultiplyNode()\n",
    "        self.w1x1_add_w2x2 = AddNode()\n",
    "        self.w1x1_w2x2_add_b = AddNode()\n",
    "        self.sigmoid = SigmoidNode()\n",
    "    \n",
    "    def forward(self):\n",
    "        w1x1 = self.w1_mul_x1.forward(self.w1, self.x1)\n",
    "        w2x2 = self.w2_mul_x2.forward(self.w2, self.x2)\n",
    "        w1x1_w2x2 = self.w1x1_add_w2x2.forward(w1x1, w2x2)\n",
    "        w1x1_w2x2_b = self.w1x1_w2x2_add_b.forward(w1x1_w2x2, self.b)\n",
    "        self.sigmoid.forward(w1x1_w2x2_b)\n",
    "        \n",
    "    def backward(self):\n",
    "        self.sigmoid.backward()\n",
    "        self.w1x1_w2x2_add_b.backward()\n",
    "        self.w1x1_add_w2x2.backward()\n",
    "        self.w2_mul_x2.backward()\n",
    "        self.w1_mul_x1.backward()\n",
    "    \n",
    "    def updateWeightsAndBias(self):\n",
    "        self.w1.value -= self.alpha * self.w1.gradient\n",
    "        self.w2.value -= self.alpha * self.w2.gradient\n",
    "        self.b.value -= self.alpha * self.b.gradient\n",
    "        \n",
    "    # For updating the inputs of the second perceptron\n",
    "    def updateInputs(self):\n",
    "        self.x1.value -= self.alpha * self.x1.gradient\n",
    "        self.x2.value -= self.alpha * self.x2.gradient        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Assignment 3\n",
    "\n",
    "```\n",
    "X1 ------\\\n",
    "          \\    X3\n",
    "          (P) ---- (P) ---- (T)\n",
    "          /        /\n",
    "X2 ------/        /\n",
    "X4---------------/\n",
    "```\n",
    "\n",
    "1. Create a two layer neural network with one perceptron in each layer (see Diagram above). Write a validation code that does along with your implementation. The goal of network is to optimize the two perceptrons to produce the output target `T` given the inputs `X1` and `X2`. Assume the output `O` of each perceptron is\n",
    "\n",
    "$$ O = \\sigma{(w1*x1 + w2*x2 + b)} $$ where\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "Feel free to change the loss function if you like.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation for double layer perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output :0.8113\tActual output :0.8113\n",
      "\n",
      "Perceptron 1 static inputs :0.1 and 0.23\n",
      "Perceptron 2 changed inputs :0.678376881237 and 0.639712580263\n"
     ]
    }
   ],
   "source": [
    "#Output Target\n",
    "T = 0.8113\n",
    "\n",
    "#Inputs for first Perceptron\n",
    "x1,x2 = (0.1, 0.23)\n",
    "\n",
    "#Dummy Inputs for second Perceptron, which will be learned\n",
    "x3,x4 = (0.112, 0.37)\n",
    "\n",
    "#Hyper parameters\n",
    "alpha = 0.1\n",
    "\n",
    "#Number of iterations\n",
    "N = 100000\n",
    "\n",
    "p1 = Perceptron(x1, x2, alpha = 0.1)\n",
    "p2 = Perceptron(x3, x4, alpha = 0.1)\n",
    "\n",
    "for i in range (N):\n",
    "    p1.forward();\n",
    "\n",
    "    #Give forward output of first Perceptron as input to second Perceptron    \n",
    "    p2.x1 = Node(p1.sigmoid.output.value, 0.0)\n",
    "\n",
    "    p2.forward()\n",
    "\n",
    "    p2.sigmoid.output.gradient = -2 * (T - p2.sigmoid.output.value)\n",
    "\n",
    "    p2.backward()\n",
    "\n",
    "    # Update both weights and inputs for 2nd perceptron\n",
    "    p2.updateWeightsAndBias()\n",
    "    p2.updateInputs()\n",
    "\n",
    "    #Changed input of 2nd perceptron is the target value for 1st perceptron\n",
    "    p1_target = p2.x1.value\n",
    "\n",
    "    p1.sigmoid.output.gradient = -2 * (p1_target - p1.sigmoid.output.value)\n",
    "\n",
    "    p1.backward()\n",
    "\n",
    "    # Update for 1st perceptron, only weights\n",
    "    p1.updateWeightsAndBias()\n",
    "\n",
    "    \n",
    "\n",
    "print \"Expected output :\" + str(T) + \"\\tActual output :\" + str(p2.sigmoid.output.value)\n",
    "print \"\\nPerceptron 1 static inputs :\" + str(p1.x1.value) + \" and \" + str(p1.x2.value)\n",
    "print \"Perceptron 2 changed inputs :\" + str(p2.x1.value) + \" and \" + str(p2.x2.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
